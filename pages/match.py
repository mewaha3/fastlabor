# pages/match.py
import streamlit as st
import pandas as pd
import json
import math
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import gspread
from oauth2client.service_account import ServiceAccountCredentials

st.set_page_config(page_title="üîç Matching Jobs", layout="wide")
st.title("üîç Matching Results")

# ------------------------------------------------------------
# 1. ‡πÇ‡∏´‡∏•‡∏î Service Account credentials ‡∏à‡∏≤‡∏Å Secrets
# ------------------------------------------------------------
# ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ .streamlit/secrets.toml ‡πÉ‡∏´‡πâ‡∏°‡∏µ [gcp].credentials
creds_dict = json.loads(st.secrets["gcp"]["credentials"])
scope = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]
creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
gc = gspread.authorize(creds)

# ------------------------------------------------------------
# 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets
# ------------------------------------------------------------
SPREADSHEET_NAME = "FAST_LABOR"
sheet = gc.open(SPREADSHEET_NAME)

ws_jobs    = sheet.worksheet("PostJob")
ws_seekers = sheet.worksheet("FindJob")

jobs_df    = pd.DataFrame(ws_jobs.get_all_records())
seekers_df = pd.DataFrame(ws_seekers.get_all_records())

# ------------------------------------------------------------
# 3. ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
# ------------------------------------------------------------
# ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:
# jobs_df:    ['job_id','required_skills','start','end','lat','lng','min_wage','max_wage']
# seekers_df: ['seeker_id','skills','avail_start','avail_end','lat','lng','expected_wage']

jobs_df['start'] = pd.to_datetime(jobs_df['start'])
jobs_df['end']   = pd.to_datetime(jobs_df['end'])
seekers_df['avail_start'] = pd.to_datetime(seekers_df['avail_start'])
seekers_df['avail_end']   = pd.to_datetime(seekers_df['avail_end'])

# ------------------------------------------------------------
# 4. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° TF-IDF ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Skill Similarity
# ------------------------------------------------------------
tfidf = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b")
corpus = list(jobs_df['required_skills']) + list(seekers_df['skills'])
tfidf_mat = tfidf.fit_transform(corpus)

job_tfidf    = tfidf_mat[: len(jobs_df)]
seeker_tfidf = tfidf_mat[len(jobs_df) :]


def skill_score(i_job: int, i_seek: int) -> float:
    """Cosine similarity ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á required_skills ‡∏Å‡∏±‡∏ö skills"""
    return cosine_similarity(job_tfidf[i_job], seeker_tfidf[i_seek])[0, 0]


def datetime_score(job: pd.Series, seeker: pd.Series) -> float:
    """1.0 ‡∏ñ‡πâ‡∏≤‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡∏°‡∏¥‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô 0.0"""
    latest_start = max(job.start, seeker.avail_start)
    earliest_end = min(job.end, seeker.avail_end)
    overlap = (earliest_end - latest_start).total_seconds()
    return 1.0 if overlap > 0 else 0.0


def haversine(lat1, lon1, lat2, lon2):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á (km) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏™‡∏π‡∏ï‡∏£ Haversine"""
    r = 6371  # ‡∏£‡∏±‡∏®‡∏°‡∏µ‡πÇ‡∏•‡∏Å (‡∏Å‡∏°.)
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    a = (
        math.sin(dlat / 2) ** 2
        + math.cos(math.radians(lat1))
        * math.cos(math.radians(lat2))
        * math.sin(dlon / 2) ** 2
    )
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    return r * c


def proximity_score(job: pd.Series, seeker: pd.Series, max_km: float = 50) -> float:
    """1.0 ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏¢‡∏∞ 0 ‡∏Å‡∏°. ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 0 ‡∏ó‡∏µ‡πà max_km"""
    dist = haversine(job.lat, job.lng, seeker.lat, seeker.lng)
    return max(0.0, 1 - dist / max_km)


def wage_score(job: pd.Series, seeker: pd.Series) -> float:
    """1.0 ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏≤‡∏à‡πâ‡∏≤‡∏á‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [min_wage,max_wage] ‡∏°‡∏¥‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô 0.0"""
    return 1.0 if (job.min_wage <= seeker.expected_wage <= job.max_wage) else 0.0


def match_score(
    job: pd.Series,
    seeker: pd.Series,
    w: dict = {"skill": 0.4, "time": 0.2, "prox": 0.2, "wage": 0.2},
) -> float:
    s1 = skill_score(job.name, seeker.name)
    s2 = datetime_score(job, seeker)
    s3 = proximity_score(job, seeker)
    s4 = wage_score(job, seeker)
    return w["skill"] * s1 + w["time"] * s2 + w["prox"] * s3 + w["wage"] * s4


# ------------------------------------------------------------
# 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå Matching
# ------------------------------------------------------------
records = []
for i, job in jobs_df.iterrows():
    for j, seeker in seekers_df.iterrows():
        score = match_score(job, seeker)
        if score > 0:
            records.append(
                {
                    "job_id": job.job_id,
                    "seeker_id": seeker.seeker_id,
                    "score": score,
                }
            )

matches = pd.DataFrame(records)
if matches.empty:
    st.info("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà match ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ")
    st.stop()

matches = matches.sort_values(["job_id", "score"], ascending=[True, False])
top_matches = matches.groupby("job_id").head(3).reset_index(drop=True)

# ------------------------------------------------------------
# 6. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô Streamlit
# ------------------------------------------------------------
for job_id, group in top_matches.groupby("job_id"):
    st.subheader(f"üìÑ Job #{job_id}")
    for _, row in group.iterrows():
        seeker = seekers_df[seekers_df.seeker_id == row.seeker_id].iloc[0]
        st.markdown(
            f"""
- **Seeker #{row.seeker_id}** ‚Äî Score: {row.score:.2f}  
  ‚Ä¢ Skills: {seeker.skills}  
  ‚Ä¢ Available: {seeker.avail_start.strftime('%Y-%m-%d %H:%M')} to {seeker.avail_end.strftime('%Y-%m-%d %H:%M')}  
  ‚Ä¢ Location: ({seeker.lat:.4f}, {seeker.lng:.4f})  
  ‚Ä¢ Expected Wage: {seeker.expected_wage}
"""
        )
    st.markdown("---")

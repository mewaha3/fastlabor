# pages/match.py
import streamlit as st
import pandas as pd
import json
import math
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials
import gspread
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

st.set_page_config(page_title="üîç Matching Jobs", layout="wide")
st.title("üîç Matching Results")

# ---------------------------------------
# 1. ‡πÇ‡∏´‡∏•‡∏î credentials ‡∏à‡∏≤‡∏Å .streamlit/secrets.toml
# ---------------------------------------
creds_dict = json.loads(st.secrets["gcp"]["credentials"])
scope = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]
creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
gc = gspread.authorize(creds)

# ---------------------------------------
# 2. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PostJob & FindJob
# ---------------------------------------
SPREADSHEET_NAME = "fastlabor"  # ‡∏ä‡∏∑‡πà‡∏≠ spreadsheet ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
sh = gc.open(SPREADSHEET_NAME)

jobs_df    = pd.DataFrame(sh.worksheet("post_job").get_all_records())
seekers_df = pd.DataFrame(sh.worksheet("find_job").get_all_records())

# ---------------------------------------
# 3. ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• & ‡∏™‡∏£‡πâ‡∏≤‡∏á datetime
# ---------------------------------------
# PostJob: skills, job_date, start_time, end_time, province, district, subdistrict, start_salary, range_salary
# FindJob: skills or job_detail, job_date, start_time, end_time, province, district, subdistrict, salary

# ‡∏ñ‡πâ‡∏≤ FindJob ‡πÉ‡∏ä‡πâ 'job_detail' ‡πÅ‡∏ó‡∏ô 'skills' ‡πÉ‡∏´‡πâ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
if "skills" not in seekers_df.columns and "job_detail" in seekers_df.columns:
    seekers_df["skills"] = seekers_df["job_detail"].astype(str)
else:
    seekers_df["skills"] = seekers_df["skills"].astype(str)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå wages
jobs_df["min_wage"] = pd.to_numeric(jobs_df["start_salary"], errors="coerce")
jobs_df["max_wage"] = pd.to_numeric(jobs_df["range_salary"], errors="coerce")
seekers_df["expected_wage"] = pd.to_numeric(seekers_df.get("salary", 0), errors="coerce")

# ‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà+‡πÄ‡∏ß‡∏•‡∏≤
def make_dt(df, date_col, time_col, out_col):
    df[out_col] = pd.to_datetime(df[date_col].astype(str) + " " + df[time_col].astype(str),
                                  errors="coerce")
make_dt(jobs_df,    "job_date",  "start_time", "start_dt")
make_dt(jobs_df,    "job_date",  "end_time",   "end_dt")
make_dt(seekers_df,"job_date",  "start_time", "avail_start")
make_dt(seekers_df,"job_date",  "end_time",   "avail_end")

# ---------------------------------------
# 4. TF-IDF for skills
# ---------------------------------------
tfidf = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b")
corpus = list(jobs_df["skills"]) + list(seekers_df["skills"])
tfidf_mat = tfidf.fit_transform(corpus)
job_tfidf    = tfidf_mat[: len(jobs_df)]
seeker_tfidf = tfidf_mat[len(jobs_df) :]

def skill_score(i, j):
    return cosine_similarity(job_tfidf[i], seeker_tfidf[j])[0, 0]

# ---------------------------------------
# 5. ‡πÄ‡∏ß‡∏•‡∏≤ & ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà & ‡∏Ñ‡πà‡∏≤‡∏à‡πâ‡∏≤‡∏á
# ---------------------------------------
def datetime_score(job, seeker):
    overlap = (min(job.end_dt, seeker.avail_end) -
               max(job.start_dt, seeker.avail_start)).total_seconds()
    return 1.0 if overlap > 0 else 0.0

def location_score(job, seeker):
    # ‡πÉ‡∏´‡πâ 1.0 ‡∏ñ‡πâ‡∏≤ province,district,subdistrict ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    return 1.0 if (
        job.province==seeker.province
        and job.district==seeker.district
        and job.subdistrict==seeker.subdistrict
    ) else 0.0

def wage_score(job, seeker):
    return 1.0 if (job.min_wage <= seeker.expected_wage <= job.max_wage) else 0.0

# ---------------------------------------
# 6. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°
# ---------------------------------------
weights = {"skill":0.4, "time":0.2, "loc":0.2, "wage":0.2}

records = []
for i, job in jobs_df.iterrows():
    for j, seeker in seekers_df.iterrows():
        s_skill = skill_score(i, j)
        s_time  = datetime_score(job, seeker)
        s_loc   = location_score(job, seeker)
        s_wage  = wage_score(job, seeker)
        total   = (weights["skill"]*s_skill
                   + weights["time"]*s_time
                   + weights["loc"]*s_loc
                   + weights["wage"]*s_wage)
        if total>0:
            records.append({
                "job_idx": i,
                "seeker_idx": j,
                "job_id":    job.job_date.strftime("%Y%m%d")+"_"+str(i),
                "seeker_id": seekers_df.loc[j,"email"],
                "score":     total
            })

matches = pd.DataFrame(records)
if matches.empty:
    st.info("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà match ‡πÑ‡∏î‡πâ")
    st.stop()

matches = matches.sort_values(["job_id","score"], ascending=[True,False])
top3 = matches.groupby("job_id").head(3)

# ---------------------------------------
# 7. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
# ---------------------------------------
for job_id, group in top3.groupby("job_id"):
    st.subheader(f"üìÑ Job {job_id}")
    job = jobs_df.loc[group["job_idx"].iloc[0]]
    st.markdown(f"**Skills:** {job.skills} ‚Äî **Date:** {job.job_date} **{job.start_time}‚Äì{job.end_time}**")
    for _, row in group.iterrows():
        seeker = seekers_df.loc[row.seeker_idx]
        st.markdown(
            f"- **Seeker:** {seeker.email} (Score {row.score:.2f})  \n"
            f"  ‚Ä¢ Skills: {seeker.skills}  \n"
            f"  ‚Ä¢ Availability: {seeker.avail_start}‚Äì{seeker.avail_end}  \n"
            f"  ‚Ä¢ Location: {seeker.province}/{seeker.district}/{seeker.subdistrict}  \n"
            f"  ‚Ä¢ Expected Wage: {seeker.expected_wage}"
        )
    st.markdown("---")
